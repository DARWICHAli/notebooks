{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiOyzRjzpW6RD/HmnZObLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DARWICHAli/notebooks/blob/main/comfort_zone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using pytorch, will train a model with any architecture , the model deduct from the data when reaching conversion, in order to apply extra attention to the neglected classes, and accelerate computation time\n",
        "\n",
        "* [ ] train loop\n",
        "* [ ] scheduler\n",
        "* [ ] conversion detectin function\n",
        "* [ ] detection on train loop\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iu_pTtUrLytd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n"
      ],
      "metadata": {
        "id": "eKQjaytu2G3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d2cbf4-cdc4-4061-e96c-a188470bed4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/805.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/805.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m788.5/805.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFkwxFOoLwBJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchmetrics.classification import ROC , AUROC\n",
        "import seaborn as sns\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import argparse\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import copy\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomAffine(degrees=15),\n",
        "    transforms.RandomPerspective(),\n",
        "    #transforms.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    #transforms.Cutout(num_holes=1, max_h_size=32, max_w_size=32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "                                    transforms.Resize((224, 224)),   #must same as here\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "jJmEXWcD1TvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(test_loader,model,mode,arch,class_names,epochs=0):\n",
        "    # Evaluate the model on test data\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "            #pred = output.argmax(dim=1, keepdim=True)\n",
        "            pred = torch.argmax(torch.softmax(output,dim=1),1)\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "            targets.extend(target.cpu().numpy())\n",
        "\n",
        "    # Create the confusion matrix\n",
        "    cm = confusion_matrix(targets, predictions)\n",
        "\n",
        "    # Plot the confusion matrix using Seaborn\n",
        "    sns.set()\n",
        "    plt.figure(figsize=(12,12))\n",
        "    sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    #sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    #plt.show()\n",
        "    # Save the plot as a PNG file\n",
        "    os.makedirs(\"results\",exist_ok=True)\n",
        "    plt.savefig(os.path.join( \"results\",f'confusion_matrix_{arch}_{mode}_in_{epochs}.png'), dpi=300, bbox_inches='tight')\n"
      ],
      "metadata": {
        "id": "yoH-S0L41aTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_plot(test_loader,model,epochs,num_class,mode,arch):\n",
        "    roc = ROC(task=\"multiclass\",num_classes=num_class)\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "            pred = torch.softmax(output,dim=1)\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "            targets.extend(target.cpu().numpy())\n",
        "\n",
        "    pred = torch.FloatTensor(predictions)\n",
        "    targ = torch.IntTensor(targets)\n",
        "    auroc = AUROC(task=\"multiclass\",num_classes=num_class,average='macro')\n",
        "\n",
        "    fpr, tpr, _ = roc(pred, targ)\n",
        "\n",
        "    # plot ROC curves\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    for i in range(num_class):\n",
        "        plt.plot(fpr[i], tpr[i], label='Class {}'.format(i))\n",
        "    plt.xlabel('False positive rate')\n",
        "    plt.ylabel('True positive rate')\n",
        "    plt.title('ROC curve for multi-class classification with AUC= {:.4f}'.format(auroc(pred,targ)))\n",
        "    plt.legend()\n",
        "    #plt.show()\n",
        "    os.makedirs(\"results\",exist_ok=True)\n",
        "    plt.savefig(os.path.join( \"results\",f'ROC_in_{arch}_{mode}_{epochs}.png'), dpi=300, bbox_inches='tight')\n"
      ],
      "metadata": {
        "id": "u_0wZJiW1f4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(train_dir):\n",
        "    #################################   dataset   ############################\n",
        "\n",
        "    train_path = os.path.join(train_dir,'train')\n",
        "    val_path = os.path.join(train_dir,'val')\n",
        "\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(train_path, transforms_train)\n",
        "    val_dataset = datasets.ImageFolder(val_path, transforms_test)\n",
        "    # Define the split ratio\n",
        "    #split_ratio = 0.8  # 80% for training, 20% for validation\n",
        "\n",
        "    # Calculate the sizes of the training and validation sets based on the split ratio\n",
        "    #train_size = int(len(train_dataset) * split_ratio)\n",
        "    #val_size = len(train_dataset) - train_size\n",
        "    #train_set, test_set = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=20, shuffle=False, num_workers=4)\n",
        "\n",
        "    class_names = train_dataset.classes\n",
        "    num_classes = len(class_names)\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=list(set(train_dataset.targets)), y=train_dataset.targets)\n",
        "    tensor_weights = torch.FloatTensor(class_weights)\n",
        "\n",
        "    return train_dataloader,train_dataset,test_dataloader,train_dataset,num_classes,tensor_weights,class_names"
      ],
      "metadata": {
        "id": "vGPkMTkg1iE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model,best,mode,train_dataloader,optimizer,criterion,train_dataset,test_dataloader,path,writer,epochs):\n",
        "\n",
        "    class_num = len(train_dataset.classes)\n",
        "    num_epochs = epochs   #(set no of epochs)\n",
        "    start_time = time.time() #(for showing time)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=5,verbose=True)\n",
        "\n",
        "    cur_epoch = best #to save final epoch if it doesn't enter to avoid crash(outside the loop)\n",
        "    for epoch in range(best,num_epochs+1): #(loop for every epoch)\n",
        "        cur_epoch = epoch\n",
        "        print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
        "        \"\"\" Training Phase \"\"\"\n",
        "        model.train()    #(training model)\n",
        "        running_loss = 0.   #(set loss 0)\n",
        "        running_corrects = 0\n",
        "        running_corrects_5 = 0\n",
        "\n",
        "        # load a batch data of images\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # forward inputs and get output\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            #_, preds = torch.max(outputs, 1)\n",
        "            preds = torch.argmax(torch.softmax(outputs, dim=1), 1)\n",
        "            _, top5_indices = torch.topk(outputs.softmax(dim=-1), k=5)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            # get loss value and update the network weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            running_corrects_5 += torch.sum(torch.any(top5_indices == labels.data.view(-1, 1), dim=1))\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
        "        epoch_acc = running_corrects / len(train_dataloader.dataset) * 100.\n",
        "        epoch_acc_5 = (running_corrects_5 / len(train_dataloader.dataset)) * 100.\n",
        "        print('[Train #{}] Loss: {:.4f} TOP1ACC: {:.4f}% TOP5ACC: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc,epoch_acc_5, time.time() - start_time))\n",
        "        writer.add_scalar('Training Loss', epoch_loss, epoch)\n",
        "        writer.add_scalar('Training Accuracy TOP1', epoch_acc, epoch)\n",
        "        writer.add_scalar('Training Accuracy TOP5', epoch_acc_5, epoch)\n",
        "\n",
        "\n",
        "        \"\"\" Testing Phase \"\"\"\n",
        "        with torch.inference_mode():\n",
        "            model.eval()\n",
        "            running_loss = 0.\n",
        "            running_corrects = 0\n",
        "            running_corrects_5 = 0.\n",
        "\n",
        "            for inputs, labels in test_dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                preds = torch.argmax(torch.softmax(outputs, dim=1), 1)\n",
        "                _, top5_indices = torch.topk(outputs.softmax(dim=-1), k=5)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                running_corrects_5 += torch.sum(torch.any(top5_indices == labels.data.view(-1, 1), dim=1))\n",
        "\n",
        "            epoch_loss = running_loss / len(test_dataloader.dataset)\n",
        "            epoch_acc = (running_corrects / len(test_dataloader.dataset)) * 100.\n",
        "            epoch_acc_5 = (running_corrects_5 / len(test_dataloader.dataset)) * 100.\n",
        "            print('[Test #{}] Loss: {:.4f} TOP1ACC: {:.4f}% TOP5ACC: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc,epoch_acc_5, time.time() - start_time))\n",
        "            writer.add_scalar('Testing Loss', epoch_loss, epoch)\n",
        "            writer.add_scalar('Testing Accuracy TOP1', epoch_acc, epoch)\n",
        "            writer.add_scalar('Testing Accuracy TOP5', epoch_acc_5, epoch)\n",
        "            scheduler.step(epoch_loss)\n",
        "        if epoch_loss < min_loss :\n",
        "            min_loss = epoch_loss\n",
        "            conf_matrix(test_dataloader,model,mode,arch,train_dataset.classes,epoch)\n",
        "            roc_plot(test_dataloader,model,epoch,class_num,mode,arch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    torch.save({\n",
        "    'epoch': cur_epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': epoch_loss\n",
        "    }, \"model.pth\")\n",
        "    conf_matrix(test_dataloader,model,mode,arch,train_dataset.classes,cur_epoch)\n",
        "    roc_plot(test_dataloader,model,cur_epoch,class_num,mode,arch)\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "FO9yLksF12FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def train_cz(model,best,dataset,dataloader,optimizer,criterion,path,writer,total_epochs):\n",
        "\n",
        "def train_cz(model,dataset,dataloader,optimizer,criterion,writer,total_epochs):\n",
        "    # Convergence parameters\n",
        "    min_loss_change = 1e-3  # Minimum change in loss to consider convergence\n",
        "    patience = 5  # Number of epochs with no improvement after which to consider convergence\n",
        "    last_10_values = []\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_loss = float('inf')\n",
        "    no_improvement_count = 0\n",
        "    scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10,verbose=True)\n",
        "    start_time = time.time()\n",
        "    for epoch in range(total_epochs):\n",
        "\n",
        "        total_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        running_corrects_5 = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            preds = torch.argmax(torch.softmax(outputs, dim=1), 1)\n",
        "            _, top5_indices = torch.topk(outputs.softmax(dim=-1), k=5)\n",
        "\n",
        "            running_corrects += torch.sum(preds == targets.data)\n",
        "            running_corrects_5 += torch.sum(torch.any(top5_indices == targets.data.view(-1, 1), dim=1))\n",
        "            epoch_acc = (running_corrects / len(dataloader.dataset)) * 100.\n",
        "            epoch_acc_5 = (running_corrects_5 / len(dataloader.dataset)) * 100.\n",
        "\n",
        "\n",
        "\n",
        "            # Calculate total loss for the epoch\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "\n",
        "\n",
        "        # Detect convergence based on change in loss\n",
        "        if epoch > 0:\n",
        "            if len(last_10_values) > 10:\n",
        "                    last_10_values.pop(0)\n",
        "\n",
        "            loss_change = avg_loss - prev_loss\n",
        "            if loss_change < min_loss_change:\n",
        "                #no_improvement_count += 1\n",
        "                last_10_values.append(-1)\n",
        "                print(f\"no improvement, no_improvement_count = {last_10_values.count(-1)}\")\n",
        "            else:\n",
        "                #no_improvement_count = 0\n",
        "                last_10_values.append(0)\n",
        "\n",
        "            if last_10_values.count(-1) >= patience:\n",
        "                last_10_values = []\n",
        "                print(f'Converged after {epoch + 1} epochs.')\n",
        "                # Modify batch composition to prioritize best-performing class\n",
        "                best_class_indices = (targets == torch.argmax(outputs, dim=1)).nonzero().squeeze()\n",
        "                random.shuffle(best_class_indices)\n",
        "                half_size = len(best_class_indices) // 2\n",
        "                subset_indices = best_class_indices[:half_size]\n",
        "                subset_sampler = SubsetRandomSampler(subset_indices)\n",
        "                #dataloader = DataLoader(dataset, batch_size=32, sampler=subset_sampler)\n",
        "                dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, sampler=subset_sampler, num_workers=2, pin_memory=True)\n",
        "                #break\n",
        "\n",
        "        # Update best model if the current model has a lower loss\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "        prev_loss = avg_loss\n",
        "        # Print training statistics\n",
        "\n",
        "        print('[Train #{}] Loss: {:.4f} TOP1ACC: {:.4f}% TOP5ACC: {:.4f}% Time: {:.4f}s'.format(epoch, avg_loss, epoch_acc,epoch_acc_5, time.time() - start_time))\n",
        "        #print(f'Epoch [{epoch + 1}/{total_epochs}], Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Training completed\n",
        "    print('Training finished.')\n",
        "    return best_model\n"
      ],
      "metadata": {
        "id": "XOgkq_Sv-2ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 classes\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "epochs = 500\n",
        "\n",
        "# Load the CIFAR-10 training and test datasets\n",
        "dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_train)\n",
        "\n",
        "# Create data loaders for training and test datasets\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "class_names = dataset.classes\n",
        "num_classes = len(class_names)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=list(set(dataset.targets)), y=dataset.targets)\n",
        "tensor_weights = torch.FloatTensor(class_weights)\n",
        "\n",
        "\n",
        "\n",
        "model = models.resnet18(ResNet18_Weights.DEFAULT)   #load resnet18 model\n",
        "\n",
        "for name ,param in model.named_parameters():\n",
        "    if 'layer4' in name :\n",
        "        param.requires_grad = True # False\n",
        "    else :\n",
        "        param.requires_grad = False # False\n",
        "num_features = model.fc.in_features     #extract fc layers features\n",
        "model.fc = nn.Sequential(nn.Linear(num_features, len(class_names)))\n",
        "model = model.to(device)\n",
        "\n",
        "tensor_weights = tensor_weights.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight = tensor_weights)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9,weight_decay=0.0001)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "log_dir = os.path.join(\"logs\",f\"resnet18\")\n",
        "\n",
        "#tmp = optimizer.param_groups[0]['lr']\n",
        "#optimizer.param_groups[0]['lr'] = 0.0001\n",
        "tmp = optimizer.param_groups[0]['lr']\n",
        "print(f'training resnet18 for {epochs}. Current lr is {tmp}.')\n",
        "writer = SummaryWriter(log_dir)\n",
        "model = train_cz(model,dataset,dataloader,optimizer,criterion,writer,epochs)\n",
        "writer.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcGLlL7MCwIM",
        "outputId": "0aba949a-ac5a-405a-e650-2bd29edff431"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training resnet18 for 500. Current lr is 0.01.\n",
            "[Test #0] Loss: 1.6034 TOP1ACC: 42.4600% TOP5ACC: 88.3700% Time: 66.4556s\n",
            "[Test #1] Loss: 1.3746 TOP1ACC: 51.7900% TOP5ACC: 92.8800% Time: 136.2132s\n",
            "[Test #2] Loss: 1.2964 TOP1ACC: 54.7300% TOP5ACC: 93.5100% Time: 203.2596s\n",
            "[Test #3] Loss: 1.2352 TOP1ACC: 57.1600% TOP5ACC: 94.2000% Time: 268.3040s\n",
            "[Test #4] Loss: 1.1775 TOP1ACC: 58.4700% TOP5ACC: 94.8800% Time: 334.0584s\n",
            "[Test #5] Loss: 1.1642 TOP1ACC: 58.9100% TOP5ACC: 95.1700% Time: 401.0149s\n",
            "[Test #6] Loss: 1.1333 TOP1ACC: 60.4200% TOP5ACC: 95.3000% Time: 468.6760s\n",
            "[Test #7] Loss: 1.0971 TOP1ACC: 60.8000% TOP5ACC: 95.5000% Time: 535.9012s\n",
            "[Test #8] Loss: 1.0740 TOP1ACC: 62.1600% TOP5ACC: 95.7700% Time: 602.9630s\n",
            "[Test #9] Loss: 1.0600 TOP1ACC: 62.9300% TOP5ACC: 95.7000% Time: 671.7839s\n",
            "[Test #10] Loss: 1.0439 TOP1ACC: 63.7800% TOP5ACC: 95.9500% Time: 739.8687s\n",
            "[Test #11] Loss: 1.0379 TOP1ACC: 62.7800% TOP5ACC: 95.9000% Time: 806.4990s\n",
            "[Test #12] Loss: 1.0299 TOP1ACC: 64.4000% TOP5ACC: 95.7600% Time: 876.0762s\n",
            "[Test #13] Loss: 1.0137 TOP1ACC: 63.7600% TOP5ACC: 96.0300% Time: 944.0571s\n",
            "[Test #14] Loss: 0.9646 TOP1ACC: 65.4300% TOP5ACC: 96.5200% Time: 1012.1694s\n",
            "[Test #15] Loss: 0.9814 TOP1ACC: 65.8200% TOP5ACC: 96.2100% Time: 1080.3167s\n",
            "[Test #16] Loss: 0.9702 TOP1ACC: 65.5000% TOP5ACC: 96.2200% Time: 1145.7997s\n",
            "[Test #17] Loss: 0.9601 TOP1ACC: 66.5200% TOP5ACC: 96.5200% Time: 1211.1579s\n",
            "[Test #18] Loss: 0.9447 TOP1ACC: 66.3600% TOP5ACC: 96.6800% Time: 1277.3864s\n",
            "[Test #19] Loss: 0.9201 TOP1ACC: 67.3000% TOP5ACC: 96.7800% Time: 1341.6145s\n",
            "[Test #20] Loss: 0.9110 TOP1ACC: 67.7300% TOP5ACC: 96.9500% Time: 1407.8944s\n",
            "[Test #21] Loss: 0.9071 TOP1ACC: 68.0100% TOP5ACC: 96.7200% Time: 1475.6091s\n",
            "[Test #22] Loss: 0.9058 TOP1ACC: 67.9600% TOP5ACC: 96.9400% Time: 1540.9871s\n",
            "[Test #23] Loss: 0.8815 TOP1ACC: 69.2800% TOP5ACC: 96.9600% Time: 1607.3917s\n",
            "[Test #24] Loss: 0.8787 TOP1ACC: 68.9600% TOP5ACC: 96.9000% Time: 1674.6661s\n",
            "[Test #25] Loss: 0.8865 TOP1ACC: 69.4000% TOP5ACC: 96.7500% Time: 1740.1693s\n",
            "[Test #26] Loss: 0.8799 TOP1ACC: 68.6100% TOP5ACC: 96.9700% Time: 1804.5900s\n",
            "[Test #27] Loss: 0.8724 TOP1ACC: 69.3000% TOP5ACC: 96.8100% Time: 1872.9089s\n",
            "[Test #28] Loss: 0.8574 TOP1ACC: 69.9400% TOP5ACC: 96.8100% Time: 1939.0320s\n",
            "no improvement, no_improvement_count = 1\n",
            "[Test #29] Loss: 0.8577 TOP1ACC: 69.5200% TOP5ACC: 96.8200% Time: 2002.9989s\n",
            "[Test #30] Loss: 0.8433 TOP1ACC: 69.9300% TOP5ACC: 97.3300% Time: 2070.4117s\n",
            "[Test #31] Loss: 0.8514 TOP1ACC: 69.9200% TOP5ACC: 97.2500% Time: 2136.4709s\n",
            "[Test #32] Loss: 0.8132 TOP1ACC: 71.1900% TOP5ACC: 97.2000% Time: 2202.6465s\n",
            "[Test #33] Loss: 0.8392 TOP1ACC: 70.8200% TOP5ACC: 97.2100% Time: 2265.9642s\n",
            "[Test #34] Loss: 0.8208 TOP1ACC: 71.1300% TOP5ACC: 97.2200% Time: 2331.5375s\n",
            "[Test #35] Loss: 0.8189 TOP1ACC: 71.4100% TOP5ACC: 97.4000% Time: 2398.3312s\n",
            "[Test #36] Loss: 0.8064 TOP1ACC: 71.8800% TOP5ACC: 97.1900% Time: 2462.3155s\n",
            "[Test #37] Loss: 0.7826 TOP1ACC: 72.4700% TOP5ACC: 97.3400% Time: 2527.2295s\n",
            "[Test #38] Loss: 0.8095 TOP1ACC: 70.9800% TOP5ACC: 97.2700% Time: 2592.6737s\n",
            "[Test #39] Loss: 0.7789 TOP1ACC: 72.4200% TOP5ACC: 97.4100% Time: 2658.7256s\n",
            "no improvement, no_improvement_count = 1\n",
            "[Test #40] Loss: 0.7786 TOP1ACC: 72.5300% TOP5ACC: 97.2800% Time: 2723.4686s\n",
            "[Test #41] Loss: 0.7741 TOP1ACC: 72.7200% TOP5ACC: 97.6700% Time: 2789.6208s\n",
            "[Test #42] Loss: 0.7653 TOP1ACC: 72.7600% TOP5ACC: 97.5900% Time: 2855.9431s\n",
            "[Test #43] Loss: 0.7689 TOP1ACC: 73.1900% TOP5ACC: 97.4300% Time: 2923.6717s\n",
            "no improvement, no_improvement_count = 2\n",
            "[Test #44] Loss: 0.7695 TOP1ACC: 72.8100% TOP5ACC: 97.4900% Time: 2989.6725s\n",
            "[Test #45] Loss: 0.7421 TOP1ACC: 73.6200% TOP5ACC: 97.5700% Time: 3054.7159s\n",
            "[Test #46] Loss: 0.7521 TOP1ACC: 73.0100% TOP5ACC: 97.7900% Time: 3122.3532s\n",
            "[Test #47] Loss: 0.7607 TOP1ACC: 72.9400% TOP5ACC: 97.4000% Time: 3187.7362s\n",
            "[Test #48] Loss: 0.7170 TOP1ACC: 74.8600% TOP5ACC: 97.5100% Time: 3252.7116s\n",
            "[Test #49] Loss: 0.7510 TOP1ACC: 73.4700% TOP5ACC: 97.2000% Time: 3318.6886s\n",
            "[Test #50] Loss: 0.7225 TOP1ACC: 73.8300% TOP5ACC: 97.8400% Time: 3382.1085s\n",
            "[Test #51] Loss: 0.7297 TOP1ACC: 74.3900% TOP5ACC: 97.5400% Time: 3447.4216s\n",
            "[Test #52] Loss: 0.7363 TOP1ACC: 74.4100% TOP5ACC: 97.3500% Time: 3515.4327s\n",
            "[Test #53] Loss: 0.7217 TOP1ACC: 74.5000% TOP5ACC: 97.5400% Time: 3580.9310s\n",
            "Epoch 00055: reducing learning rate of group 0 to 1.0000e-03.\n",
            "[Test #54] Loss: 0.7312 TOP1ACC: 74.6700% TOP5ACC: 97.6400% Time: 3646.1370s\n",
            "[Test #55] Loss: 0.6836 TOP1ACC: 76.3900% TOP5ACC: 97.7800% Time: 3714.1757s\n",
            "[Test #56] Loss: 0.6351 TOP1ACC: 77.7100% TOP5ACC: 97.9700% Time: 3780.0585s\n",
            "[Test #57] Loss: 0.6408 TOP1ACC: 77.3200% TOP5ACC: 97.7600% Time: 3847.2841s\n",
            "[Test #58] Loss: 0.6257 TOP1ACC: 77.9000% TOP5ACC: 97.9700% Time: 3911.1576s\n",
            "[Test #59] Loss: 0.6230 TOP1ACC: 78.0700% TOP5ACC: 98.0100% Time: 3973.3457s\n",
            "[Test #60] Loss: 0.6194 TOP1ACC: 78.4400% TOP5ACC: 97.9800% Time: 4037.2751s\n",
            "[Test #61] Loss: 0.6049 TOP1ACC: 78.4600% TOP5ACC: 98.1800% Time: 4100.0487s\n",
            "[Test #62] Loss: 0.6235 TOP1ACC: 77.9000% TOP5ACC: 97.8300% Time: 4161.8131s\n",
            "[Test #63] Loss: 0.5983 TOP1ACC: 79.0100% TOP5ACC: 98.1300% Time: 4225.2661s\n",
            "[Test #64] Loss: 0.6034 TOP1ACC: 78.2500% TOP5ACC: 98.2900% Time: 4286.8952s\n",
            "[Test #65] Loss: 0.6113 TOP1ACC: 78.5300% TOP5ACC: 98.0500% Time: 4350.1597s\n",
            "[Test #66] Loss: 0.5943 TOP1ACC: 78.9800% TOP5ACC: 98.2400% Time: 4414.0832s\n",
            "[Test #67] Loss: 0.6034 TOP1ACC: 79.2300% TOP5ACC: 97.8400% Time: 4476.4850s\n",
            "[Test #68] Loss: 0.5957 TOP1ACC: 78.7800% TOP5ACC: 98.2900% Time: 4540.0963s\n",
            "[Test #69] Loss: 0.6146 TOP1ACC: 78.2600% TOP5ACC: 98.2000% Time: 4604.7941s\n",
            "[Test #70] Loss: 0.6027 TOP1ACC: 78.9800% TOP5ACC: 98.2200% Time: 4667.5410s\n",
            "[Test #71] Loss: 0.5998 TOP1ACC: 78.8000% TOP5ACC: 97.9700% Time: 4730.2859s\n",
            "[Test #72] Loss: 0.5909 TOP1ACC: 79.0100% TOP5ACC: 98.2600% Time: 4794.3540s\n",
            "[Test #73] Loss: 0.6044 TOP1ACC: 78.8700% TOP5ACC: 97.9300% Time: 4856.9790s\n",
            "[Test #74] Loss: 0.5833 TOP1ACC: 78.9200% TOP5ACC: 98.3700% Time: 4918.6674s\n",
            "[Test #75] Loss: 0.5868 TOP1ACC: 79.1400% TOP5ACC: 97.9500% Time: 4981.4292s\n",
            "[Test #76] Loss: 0.5682 TOP1ACC: 80.0100% TOP5ACC: 98.2400% Time: 5043.2989s\n",
            "no improvement, no_improvement_count = 1\n",
            "[Test #77] Loss: 0.5684 TOP1ACC: 79.5300% TOP5ACC: 98.2000% Time: 5107.4445s\n",
            "[Test #78] Loss: 0.5886 TOP1ACC: 79.1600% TOP5ACC: 98.2000% Time: 5170.0781s\n",
            "[Test #79] Loss: 0.5842 TOP1ACC: 79.3600% TOP5ACC: 98.3300% Time: 5232.6702s\n",
            "[Test #80] Loss: 0.5866 TOP1ACC: 79.0300% TOP5ACC: 98.4100% Time: 5296.2601s\n",
            "[Test #81] Loss: 0.5639 TOP1ACC: 79.8000% TOP5ACC: 98.5100% Time: 5360.4281s\n",
            "[Test #82] Loss: 0.5621 TOP1ACC: 80.6100% TOP5ACC: 98.3800% Time: 5424.2248s\n",
            "[Test #83] Loss: 0.5771 TOP1ACC: 79.9000% TOP5ACC: 98.2300% Time: 5489.4790s\n",
            "[Test #84] Loss: 0.5831 TOP1ACC: 79.0200% TOP5ACC: 98.0300% Time: 5553.7327s\n",
            "[Test #85] Loss: 0.5721 TOP1ACC: 79.7400% TOP5ACC: 98.2900% Time: 5619.8414s\n",
            "[Test #86] Loss: 0.5733 TOP1ACC: 79.9100% TOP5ACC: 98.1000% Time: 5685.4956s\n",
            "[Test #87] Loss: 0.5677 TOP1ACC: 79.7000% TOP5ACC: 98.3700% Time: 5749.9724s\n",
            "Epoch 00089: reducing learning rate of group 0 to 1.0000e-04.\n",
            "[Test #88] Loss: 0.5624 TOP1ACC: 80.5400% TOP5ACC: 98.3400% Time: 5816.2386s\n",
            "[Test #89] Loss: 0.5668 TOP1ACC: 80.0700% TOP5ACC: 98.3800% Time: 5883.8060s\n",
            "[Test #90] Loss: 0.5622 TOP1ACC: 80.0600% TOP5ACC: 98.3900% Time: 5947.3867s\n",
            "[Test #91] Loss: 0.5714 TOP1ACC: 79.9900% TOP5ACC: 98.1200% Time: 6011.6783s\n",
            "[Test #92] Loss: 0.5649 TOP1ACC: 80.0700% TOP5ACC: 98.2900% Time: 6076.1658s\n",
            "[Test #93] Loss: 0.5810 TOP1ACC: 79.9000% TOP5ACC: 98.2100% Time: 6141.1297s\n",
            "Epoch 00095: reducing learning rate of group 0 to 1.0000e-05.\n",
            "[Test #94] Loss: 0.5623 TOP1ACC: 80.4200% TOP5ACC: 98.3000% Time: 6204.5099s\n",
            "[Test #95] Loss: 0.5506 TOP1ACC: 80.9000% TOP5ACC: 98.2400% Time: 6269.2704s\n",
            "[Test #96] Loss: 0.5714 TOP1ACC: 79.8400% TOP5ACC: 98.1100% Time: 6335.2409s\n",
            "[Test #97] Loss: 0.5628 TOP1ACC: 80.2400% TOP5ACC: 98.2600% Time: 6399.8623s\n",
            "no improvement, no_improvement_count = 1\n",
            "[Test #98] Loss: 0.5626 TOP1ACC: 79.9600% TOP5ACC: 98.3800% Time: 6464.2331s\n",
            "[Test #99] Loss: 0.5482 TOP1ACC: 80.4600% TOP5ACC: 98.4100% Time: 6529.5392s\n",
            "[Test #100] Loss: 0.5515 TOP1ACC: 80.2700% TOP5ACC: 98.3200% Time: 6593.5396s\n",
            "[Test #101] Loss: 0.5650 TOP1ACC: 80.0300% TOP5ACC: 98.2600% Time: 6658.0627s\n",
            "[Test #102] Loss: 0.5672 TOP1ACC: 80.0200% TOP5ACC: 98.2800% Time: 6721.1502s\n",
            "[Test #103] Loss: 0.5594 TOP1ACC: 80.4800% TOP5ACC: 98.2800% Time: 6784.9250s\n",
            "[Test #104] Loss: 0.5745 TOP1ACC: 80.0300% TOP5ACC: 98.0400% Time: 6850.0028s\n",
            "Epoch 00106: reducing learning rate of group 0 to 1.0000e-06.\n",
            "[Test #105] Loss: 0.5579 TOP1ACC: 80.4400% TOP5ACC: 98.1400% Time: 6914.7018s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #106] Loss: 0.5628 TOP1ACC: 79.9300% TOP5ACC: 98.2300% Time: 6980.4388s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #107] Loss: 0.5516 TOP1ACC: 80.5800% TOP5ACC: 98.1300% Time: 7046.2793s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #108] Loss: 0.5655 TOP1ACC: 80.0700% TOP5ACC: 98.0900% Time: 7113.8415s\n",
            "[Test #109] Loss: 0.5568 TOP1ACC: 80.5100% TOP5ACC: 98.3400% Time: 7178.4281s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #110] Loss: 0.5691 TOP1ACC: 80.0100% TOP5ACC: 98.1000% Time: 7244.1167s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in:   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "self._shutdown_workers()AssertionError\n",
            ":   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "can only test a child process    \n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in:     assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            ": can only test a child process    \n",
            "self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>if w.is_alive():\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "self._shutdown_workers()\n",
            "AssertionError:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "can only test a child process    if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00112: reducing learning rate of group 0 to 1.0000e-07.\n",
            "[Test #111] Loss: 0.5638 TOP1ACC: 80.4800% TOP5ACC: 98.1600% Time: 7311.7400s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #112] Loss: 0.5481 TOP1ACC: 81.0100% TOP5ACC: 98.4200% Time: 7378.0547s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child processException ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #113] Loss: 0.5604 TOP1ACC: 80.1700% TOP5ACC: 98.3600% Time: 7443.5438s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child processException ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>    \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    self._shutdown_workers()if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "if w.is_alive():AssertionError\n",
            ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child process    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "Exception ignored in: AssertionError: can only test a child process\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #114] Loss: 0.5553 TOP1ACC: 80.4500% TOP5ACC: 98.2800% Time: 7512.3827s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    \n",
            "self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "        if w.is_alive():if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0><function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "if w.is_alive():    \n",
            "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
            "can only test a child processAssertionError\n",
            ": can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #115] Loss: 0.5623 TOP1ACC: 80.3200% TOP5ACC: 98.1500% Time: 7577.0172s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    AssertionError: self._shutdown_workers()can only test a child process\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>if w.is_alive():\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    : if w.is_alive():can only test a child process\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "\n",
            "AssertionErrorTraceback (most recent call last):\n",
            ": can only test a child process  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test #116] Loss: 0.5518 TOP1ACC: 80.5800% TOP5ACC: 98.3300% Time: 7643.5228s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    Exception ignored in: if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a4e25b925f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test #117] Loss: 0.5686 TOP1ACC: 79.8900% TOP5ACC: 98.1900% Time: 7710.6775s\n"
          ]
        }
      ]
    }
  ]
}